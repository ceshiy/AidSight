# æ¨¡å‹è®­ç»ƒæ•™ç¨‹

æœ¬æ–‡æ¡£ä»‹ç»å¦‚ä½•è®­ç»ƒ AidSight æ‰€éœ€çš„ YOLO ç›®æ ‡æ£€æµ‹æ¨¡å‹ã€‚

## ğŸ“‹ å‡†å¤‡å·¥ä½œ

### ç¯å¢ƒè¦æ±‚
- MindSpore 2.2+
- MindYOLO
- Python 3.9+
- GPUï¼ˆæ¨èï¼‰æˆ– NPU

### å®‰è£… MindYOLO
```bash
# å…‹éš† MindYOLO ä»“åº“
cd ~
git clone https://github.com/mindspore-lab/mindyolo.git
cd mindyolo

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å®‰è£… MindYOLO
pip install -e .
```

## ğŸ“Š æ•°æ®é›†å‡†å¤‡

### 1. éšœç¢ç‰©æ£€æµ‹æ•°æ®é›†

#### æ¨èæ•°æ®é›†
- **COCO æ•°æ®é›†**: åŒ…å«è¡Œäººã€è½¦è¾†ç­‰å¸¸è§éšœç¢ç‰©
- **Pascal VOC**: ç»å…¸ç›®æ ‡æ£€æµ‹æ•°æ®é›†
- **è‡ªå®šä¹‰æ•°æ®é›†**: é’ˆå¯¹ç‰¹å®šåœºæ™¯æ ‡æ³¨

#### COCO æ•°æ®é›†ä¸‹è½½
```bash
# åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p data/obstacle
cd data/obstacle

# ä¸‹è½½ COCO 2017
wget http://images.cocodataset.org/zips/train2017.zip
wget http://images.cocodataset.org/zips/val2017.zip
wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip

# è§£å‹
unzip train2017.zip
unzip val2017.zip
unzip annotations_trainval2017.zip

# ç›®å½•ç»“æ„
# data/obstacle/
# â”œâ”€â”€ train2017/
# â”œâ”€â”€ val2017/
# â””â”€â”€ annotations/
#     â”œâ”€â”€ instances_train2017.json
#     â””â”€â”€ instances_val2017.json
```

#### è½¬æ¢ä¸º YOLO æ ¼å¼
```bash
# ä½¿ç”¨è½¬æ¢è„šæœ¬
python data/scripts/coco_to_yolo.py \
    --json data/obstacle/annotations/instances_train2017.json \
    --output data/obstacle/labels
```

### 2. çº¢ç»¿ç¯æ£€æµ‹æ•°æ®é›†

#### æ¨èæ•°æ®é›†
- **LISA Traffic Light Dataset**
- **Bosch Small Traffic Lights Dataset**
- **è‡ªå®šä¹‰é‡‡é›†**: åœ¨æœ¬åœ°ç¯å¢ƒé‡‡é›†çº¢ç»¿ç¯å›¾åƒ

#### è‡ªå®šä¹‰æ•°æ®é‡‡é›†
```python
# ä½¿ç”¨æ‘„åƒå¤´é‡‡é›†çº¢ç»¿ç¯å›¾åƒ
import cv2
import os

cap = cv2.VideoCapture(0)
save_dir = 'data/traffic_light/images'
os.makedirs(save_dir, exist_ok=True)

count = 0
print("æŒ‰ç©ºæ ¼é”®ä¿å­˜å›¾åƒï¼ŒæŒ‰ 'q' é€€å‡º")

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    cv2.imshow('Capture', frame)
    key = cv2.waitKey(1)
    
    if key == ord(' '):  # ç©ºæ ¼é”®ä¿å­˜
        filename = os.path.join(save_dir, f'traffic_{count:04d}.jpg')
        cv2.imwrite(filename, frame)
        print(f"å·²ä¿å­˜: {filename}")
        count += 1
    elif key == ord('q'):  # q é”®é€€å‡º
        break

cap.release()
cv2.destroyAllWindows()
```

### 3. æ•°æ®æ ‡æ³¨

#### ä½¿ç”¨ LabelImg
```bash
# å®‰è£… LabelImg
pip install labelImg

# å¯åŠ¨æ ‡æ³¨å·¥å…·
labelimg data/obstacle/images data/obstacle/labels
```

**æ ‡æ³¨æµç¨‹**:
1. æ‰“å¼€å›¾åƒ
2. æŒ‰ 'w' åˆ›å»ºè¾¹ç•Œæ¡†
3. é€‰æ‹©ç±»åˆ«
4. ä¿å­˜æ ‡æ³¨ï¼ˆYOLO æ ¼å¼ï¼‰
5. ä¸‹ä¸€å¼ å›¾åƒï¼ˆæŒ‰ 'd'ï¼‰

#### ç±»åˆ«å®šä¹‰

**éšœç¢ç‰©ç±»åˆ«** (`obstacle_classes.txt`):
```
person
bicycle
car
motorcycle
bus
truck
```

**çº¢ç»¿ç¯ç±»åˆ«** (`traffic_classes.txt`):
```
red
yellow
green
```

### 4. æ•°æ®é›†åˆ’åˆ†

```python
# data/scripts/split_dataset.py
import os
import random
from shutil import copyfile

def split_dataset(images_dir, labels_dir, train_ratio=0.8):
    """å°†æ•°æ®é›†åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†"""
    
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    images = [f for f in os.listdir(images_dir) if f.endswith('.jpg')]
    random.shuffle(images)
    
    # åˆ’åˆ†
    split_idx = int(len(images) * train_ratio)
    train_images = images[:split_idx]
    val_images = images[split_idx:]
    
    # åˆ›å»ºç›®å½•
    for subset in ['train', 'val']:
        os.makedirs(f'data/obstacle/{subset}/images', exist_ok=True)
        os.makedirs(f'data/obstacle/{subset}/labels', exist_ok=True)
    
    # å¤åˆ¶æ–‡ä»¶
    for img in train_images:
        # å¤åˆ¶å›¾åƒå’Œæ ‡æ³¨
        pass
    
    print(f"è®­ç»ƒé›†: {len(train_images)}, éªŒè¯é›†: {len(val_images)}")

if __name__ == '__main__':
    split_dataset('data/obstacle/images', 'data/obstacle/labels')
```

## ğŸ‹ï¸ æ¨¡å‹è®­ç»ƒ

### 1. é…ç½®æ–‡ä»¶

åˆ›å»º `models/configs/yolov7_obstacle.yaml`:

```yaml
# YOLOv7 éšœç¢ç‰©æ£€æµ‹é…ç½®

model:
  type: YOLOv7
  backbone:
    type: ELANNet
  neck:
    type: ELANFPN
  head:
    type: YOLOv7Head
    num_classes: 6  # éšœç¢ç‰©ç±»åˆ«æ•°

data:
  train:
    dataset:
      type: COCODataset
      data_root: data/obstacle
      ann_file: train2017
      img_prefix: train2017
    transforms:
      - type: Resize
        size: [640, 640]
      - type: RandomFlip
        prob: 0.5
      - type: Normalize
        mean: [0, 0, 0]
        std: [255, 255, 255]
    
  val:
    dataset:
      type: COCODataset
      data_root: data/obstacle
      ann_file: val2017
      img_prefix: val2017

train:
  batch_size: 16
  epochs: 300
  optimizer:
    type: SGD
    lr: 0.01
    momentum: 0.9
    weight_decay: 0.0005
  lr_scheduler:
    type: CosineAnnealing
    T_max: 300
```

### 2. è®­ç»ƒè„šæœ¬

åˆ›å»º `models/train.py`:

```python
"""
æ¨¡å‹è®­ç»ƒè„šæœ¬
"""
import mindspore as ms
from mindspore import nn, context
from mindyolo.models import create_model
from mindyolo.data import create_dataloader
from mindyolo.utils import load_config

def train():
    # è®¾ç½®ä¸Šä¸‹æ–‡
    context.set_context(mode=context.GRAPH_MODE, device_target="GPU")
    
    # åŠ è½½é…ç½®
    cfg = load_config('models/configs/yolov7_obstacle.yaml')
    
    # åˆ›å»ºæ¨¡å‹
    model = create_model(
        model_name='yolov7',
        num_classes=cfg['model']['head']['num_classes']
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = create_dataloader(cfg['data']['train'])
    val_loader = create_dataloader(cfg['data']['val'])
    
    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    loss_fn = nn.SoftmaxCrossEntropyWithLogits(sparse=True)
    optimizer = nn.SGD(
        model.trainable_params(),
        learning_rate=cfg['train']['optimizer']['lr']
    )
    
    # è®­ç»ƒå¾ªç¯
    epochs = cfg['train']['epochs']
    for epoch in range(epochs):
        # è®­ç»ƒä¸€ä¸ª epoch
        model.set_train()
        for batch in train_loader:
            # å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­
            pass
        
        # éªŒè¯
        if epoch % 10 == 0:
            model.set_train(False)
            # éªŒè¯é€»è¾‘
            pass
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        if epoch % 50 == 0:
            ms.save_checkpoint(model, f'models/checkpoints/yolov7_epoch_{epoch}.ckpt')

if __name__ == '__main__':
    train()
```

### 3. å¯åŠ¨è®­ç»ƒ

```bash
# å•å¡è®­ç»ƒ
python models/train.py --config models/configs/yolov7_obstacle.yaml

# å¤šå¡è®­ç»ƒ
mpirun -n 4 python models/train.py --config models/configs/yolov7_obstacle.yaml --distributed

# ä½¿ç”¨æ˜‡è…¾ NPU è®­ç»ƒ
python models/train.py --device_target Ascend
```

### 4. ç›‘æ§è®­ç»ƒè¿‡ç¨‹

```python
# ä½¿ç”¨ TensorBoard ç›‘æ§
from mindspore.train.callback import TensorboardCallback

# åœ¨è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ å›è°ƒ
tensorboard_cb = TensorboardCallback(log_dir='./logs')
```

æŸ¥çœ‹è®­ç»ƒæ›²çº¿:
```bash
tensorboard --logdir=./logs --port=6006
```

## ğŸ“ˆ æ¨¡å‹è¯„ä¼°

### è¯„ä¼°è„šæœ¬

åˆ›å»º `models/eval.py`:

```python
"""
æ¨¡å‹è¯„ä¼°è„šæœ¬
"""
import mindspore as ms
from mindyolo.models import create_model
from mindyolo.data import create_dataloader
from mindyolo.utils import load_config, calculate_map

def evaluate():
    # åŠ è½½é…ç½®å’Œæ¨¡å‹
    cfg = load_config('models/configs/yolov7_obstacle.yaml')
    model = create_model('yolov7', num_classes=6)
    
    # åŠ è½½æƒé‡
    ms.load_checkpoint('models/checkpoints/best.ckpt', model)
    
    # åˆ›å»ºéªŒè¯æ•°æ®åŠ è½½å™¨
    val_loader = create_dataloader(cfg['data']['val'])
    
    # è¯„ä¼°
    model.set_train(False)
    results = []
    
    for batch in val_loader:
        outputs = model(batch['images'])
        results.append(outputs)
    
    # è®¡ç®— mAP
    map_score = calculate_map(results, val_loader.dataset)
    print(f"mAP@0.5: {map_score:.4f}")

if __name__ == '__main__':
    evaluate()
```

è¿è¡Œè¯„ä¼°:
```bash
python models/eval.py --checkpoint models/checkpoints/best.ckpt
```

## ğŸ”„ æ¨¡å‹å¯¼å‡º

### å¯¼å‡ºä¸º ONNX

åˆ›å»º `models/export.py`:

```python
"""
æ¨¡å‹å¯¼å‡ºè„šæœ¬
"""
import mindspore as ms
from mindyolo.models import create_model

def export_onnx():
    # åˆ›å»ºæ¨¡å‹
    model = create_model('yolov7', num_classes=6)
    
    # åŠ è½½æƒé‡
    ms.load_checkpoint('models/checkpoints/best.ckpt', model)
    
    # è®¾ç½®ä¸ºæ¨ç†æ¨¡å¼
    model.set_train(False)
    
    # å¯¼å‡º ONNX
    input_shape = [1, 3, 640, 640]
    input_tensor = ms.Tensor(np.random.randn(*input_shape), ms.float32)
    
    ms.export(
        model,
        input_tensor,
        file_name='models/yolov7_obstacle',
        file_format='ONNX'
    )
    
    print("æ¨¡å‹å·²å¯¼å‡ºä¸º ONNX æ ¼å¼")

if __name__ == '__main__':
    export_onnx()
```

è¿è¡Œå¯¼å‡º:
```bash
python models/export.py
```

## ğŸ¯ è¶…å‚æ•°è°ƒä¼˜

### é‡è¦è¶…å‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è°ƒä¼˜å»ºè®® |
|------|--------|----------|
| å­¦ä¹ ç‡ | 0.01 | å°è¯• 0.001-0.1 |
| batch_size | 16 | æ ¹æ® GPU å†…å­˜è°ƒæ•´ |
| è¾“å…¥å°ºå¯¸ | 640x640 | æ›´å¤§å°ºå¯¸æé«˜ç²¾åº¦ä½†é™ä½é€Ÿåº¦ |
| æ•°æ®å¢å¼º | ä¸­ç­‰ | å¢åŠ éšæœºè£å‰ªã€æ—‹è½¬ç­‰ |
| Anchor å¤§å° | é¢„è®¾ | æ ¹æ®æ•°æ®é›†èšç±»è°ƒæ•´ |

### å­¦ä¹ ç‡è°ƒåº¦

```python
# ä½¿ç”¨ä½™å¼¦é€€ç«
from mindspore.nn.learning_rate_schedule import CosineDecayLR

lr_schedule = CosineDecayLR(
    min_lr=0.0001,
    max_lr=0.01,
    decay_steps=300 * steps_per_epoch
)
```

## ğŸ“Š ç»“æœåˆ†æ

### è®­ç»ƒæŒ‡æ ‡

ç›‘æ§ä»¥ä¸‹æŒ‡æ ‡:
- **Loss**: åº”æŒç»­ä¸‹é™
- **mAP@0.5**: éªŒè¯é›†ä¸Šçš„å¹³å‡ç²¾åº¦
- **Precision**: ç²¾ç¡®ç‡
- **Recall**: å¬å›ç‡
- **FPS**: æ¨ç†é€Ÿåº¦

### å¸¸è§é—®é¢˜

**è¿‡æ‹Ÿåˆ**:
- å¢åŠ æ•°æ®å¢å¼º
- ä½¿ç”¨ Dropout
- å‡å°æ¨¡å‹å®¹é‡
- æ—©åœ

**æ¬ æ‹Ÿåˆ**:
- å¢åŠ æ¨¡å‹å®¹é‡
- è®­ç»ƒæ›´å¤š epoch
- æé«˜å­¦ä¹ ç‡
- æ£€æŸ¥æ•°æ®è´¨é‡

**æ¨ç†é€Ÿåº¦æ…¢**:
- å‡å°è¾“å…¥å°ºå¯¸
- ä½¿ç”¨è½»é‡åŒ–æ¨¡å‹
- æ¨¡å‹å‰ªæ
- é‡åŒ–

## ğŸ”— ç›¸å…³èµ„æº

- [MindYOLO å®˜æ–¹æ–‡æ¡£](https://github.com/mindspore-lab/mindyolo)
- [YOLO ç³»åˆ—è®ºæ–‡](https://arxiv.org/abs/2207.02696)
- [æ•°æ®å¢å¼ºæŠ€æœ¯](https://github.com/albumentations-team/albumentations)
- [æ¨¡å‹å‹ç¼©æŠ€æœ¯](https://github.com/microsoft/nni)

---

**ä¸‹ä¸€æ­¥**: å‚è€ƒ[éƒ¨ç½²æŒ‡å—](deployment.md)å°†è®­ç»ƒå¥½çš„æ¨¡å‹éƒ¨ç½²åˆ°æ˜‡è…¾è®¾å¤‡ã€‚
